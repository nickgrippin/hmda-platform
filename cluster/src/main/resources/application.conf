akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  loglevel = ${?HMDA_LOGLEVEL}
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  http.parsing.max-content-length = 2G
  http.server.default-host-header = "cfpb.gov"

  actor {
    provider = cluster
  }

  remote {
    log-remote-lifecycle-events = error
    netty.tcp {
      hostname = ${clustering.ip}
      port = ${clustering.port}
    }
  }

  cluster {
    roles = [api, persistence, query, publication]
    failure-detector.threshold = 36 //Increase value for AWS environments
    metrics.enabled = off

    retry-unsuccessful-join-after = 200s

    http {
      management {
        hostname = "127.0.0.1"
        port = 9999
      }
    }

    metrics.enabled = off

    use-dispatcher = cluster-dispatcher

    auto-down-unreachable-after = off

  }

  extensions = [
    "de.heikoseeberger.constructr.ConstructrExtension",
    "akka.cluster.client.ClusterClientReceptionist",
    "akka.cluster.pubsub.DistributedPubSub"
  ]

  quartz {
    defaultTimezone = "EST"
    threadPool.threadCount = 2
    schedules {
      AporCalculator {
        description = "Retrieve APOR tables from S3 on a schedule"
        //expression = "*/30 * * ? * *"
        expression = "0 0 23 ? * *"
        expression = ${?APOR_DATA_LOAD_SCHEDULE}
      }
    }
  }
}

constructr.coordination.nodes = [${hmda.zookeeperHost}":"${hmda.zookeeperPort}]

hmda {
  actor {
    timeout = 50
  }

  persistent-actor-timeout = 3600

  isDemo = false
  isDemo = ${?HMDA_IS_DEMO}
  zookeeperHost = "192.168.99.100"
  zookeeperHost = ${?ZOOKEEPER_HOST}
  zookeeperPort = 2181
  zookeeperPort = ${?ZOOKEEPER_PORT}
}

clustering {
  name = "hmda"
  name = ${?HMDA_CLUSTER_NAME}
  ip = "127.0.0.1"
  ip = ${?HMDA_CLUSTER_IP}
  port = 0
  port = ${?APP_PORT}
}

cluster-dispatcher {
  type = "Dispatcher"
  executor = "fork-join-executor"
  fork-join-executor {
    parallelism-min = 2
    parallelism-max = 4
  }
}

